{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relative Entropy Policy Search\n",
    "Policy search is a subfield in reinforcement learning, which aims to find good parameters for a given policy parametrization.\n",
    "\n",
    "Now we want to perform another policy update approach from an information theory perspective. Natural policy gradient algorithms always require a user-specified learning rate, an issue which was alleviated by EM algorithms. However, EM-based algorithms have other problems concerning premature convergence and the stability of learning process as they typically do not stay close to data.\n",
    "\n",
    "REPS takes the same bound in NAC algorithms and uses weighted maximum likelihood to update its policy, which donot require a learning rate. REPS formulates policy search as an optimization problem, with the following bound\n",
    "<img src=\"img/bound.png\", style=\"max-width:60%; width: 60%\">\n",
    "To solve this problem, we have to find the parameter n by minimizing the dual function:\n",
    "\n",
    "<img src=\"img/dual.png\", style=\"max-width:60%; width: 60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
